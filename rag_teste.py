import os

import dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_ollama import OllamaEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter

from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

dotenv.load_dotenv()

URL_QDRANT = os.getenv("URL_QDRANT", "http://localhost:6333")
NOME_COLECAO = os.getenv("NOME_COLECAO", "documentacao_teste")
MODEL_EMBEDDING = os.getenv("MODEL_EMBEDDING", "nomic-embed-text:v1.5")

file_path = "./100_historias_infantis.pdf"
loader = PyPDFLoader(file_path)
docs = loader.load()

print(f"::: {docs[0].page_content[:200]}\n")
print(f"::: {docs[0].metadata}\n")
print(f"::: {len(docs)}\n")

text_splitter = RecursiveCharacterTextSplitter(
    length_function=len,  # Fun√ß√£o que calcula o tamanho do texto
    is_separator_regex=False,  # Se o separador √© uma express√£o regular
    chunk_size=1000,  # Tamanho m√°ximo de cada peda√ßo (em caracteres)
    chunk_overlap=200,  # Quantos caracteres ele pega 'emprestado' do peda√ßo anterior
    add_start_index=True,
    separators=[
        "\n\n",
        "\n",
        ".",
        " ",
        "",
    ],  # Ordem de prefer√™ncia para o corte (tenta n√£o quebrar par√°grafos, depois frases...)
)

# 2. Dividindo o texto
all_splits = text_splitter.split_documents(docs)
print(f"Texto dividido em {len(all_splits)} chunks. Gerando embeddings...")

# 4. Configurando o modelo de Embeddings
# Embeddings s√£o representa√ß√µes num√©ricas (vetoriais) do texto.
# Aqui usamos o modelo "nomic-embed-text:v1.5", que roda localmente via Ollama.
# √â ele que vai converter cada peda√ßo de texto em uma lista de n√∫meros (ex: [0.12, -0.45, 0.89...]).
embeddings = OllamaEmbeddings(model=MODEL_EMBEDDING)

# 5. Inicializando o cliente do Qdrant
# O QdrantClient √© a ferramenta oficial do Qdrant para conversar com o banco de dados.
# Ele se conecta √† URL onde o seu Qdrant est√° rodando (por padr√£o: http://localhost:6333)
client = QdrantClient(url=URL_QDRANT)

# 6. Preparando o ambiente (Reset da cole√ß√£o)
# Antes de adicionar textos novos, verificamos se j√° existe uma cole√ß√£o com esse nome.
# Se existir, a gente a deleta para come√ßar do zero com uma "lousa em branco" e n√£o misturar dados.
if client.collection_exists(collection_name=NOME_COLECAO):
    client.delete_collection(collection_name=NOME_COLECAO)

# 7. Criando a cole√ß√£o no Qdrant
# Uma "cole√ß√£o" no Qdrant √© como se fosse uma tabela de banco de dados, mas otimizada para vetores.
# Aqui precisamos dizer o tamanho do vetor (size=768 √© o padr√£o do nomic-embed) e como
# calcular a proximidade entre os textos (Distance.COSINE √© o c√°lculo matem√°tico mais usado para textos).
# Nota: usamos 'create_collection' em vez de 'recreate_collection' para evitar o aviso de deprecia√ß√£o.
client.create_collection(
    collection_name=NOME_COLECAO,
    vectors_config=VectorParams(size=768, distance=Distance.COSINE),
)

# 8. O VectorStore do LangChain
# Essa classe (QdrantVectorStore) √© a "ponte" entre a intelig√™ncia do LangChain e o banco Qdrant.
# Entregamos a ela: o modelo que gera os vetores (embeddings), o cliente do banco (client)
# e o local onde isso vai ficar (collection_name).
vectorstore = QdrantVectorStore(
    embedding=embeddings,
    client=client,
    collection_name=NOME_COLECAO,
)

# 9. Adicionando os textos ao banco
# Aqui a m√°gica acontece! Esse comando pega todos os seus 'peda√ßos' de texto, envia
# para o Ollama converter em n√∫meros (embeddings), e salva tudo l√° na cole√ß√£o do Qdrant.
vectorstore.add_documents(documents=all_splits)
print("‚úÖ Tudo salvo no Qdrant com sucesso!\n")

# 10. Fazendo a busca (Retrieval)
# √â a hora da "Pesquisa Sem√¢ntica". Voc√™ manda uma pergunta ("O que √© MCP?").
# Essa pergunta tamb√©m √© convertida em um vetor, e o Qdrant procura no banco
# quais vetores (documentos) est√£o matematicamente mais 'pr√≥ximos' (Distance.COSINE) do vetor da pergunta.
# O 'k=2' diz para ele retornar os 2 melhores resultados.
print("üîç Fazendo uma busca por similaridade...")
resultados = vectorstore.similarity_search("Quem usava um macac√£o azul?", k=2)

print("\n--- Resultados Encontrados ---")
for i, doc in enumerate(resultados):
    print(f"Documento {i+1}:")
    print(doc.page_content)
    print("-" * 20)
