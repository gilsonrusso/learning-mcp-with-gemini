ğŸ’£ PARTE 2 â€” Perguntas DifÃ­ceis + Respostas Preparadas

Aqui estÃ£o as perguntas que um dev sÃªnior realmente vai fazer.

â“1. â€œPor que nÃ£o chamar a API direto do LangChain?â€
Resposta:

Porque vocÃª cria:

Acoplamento com framework

DependÃªncia de modelo

RepetiÃ§Ã£o de lÃ³gica

Falta de governanÃ§a central

O MCP:

Centraliza integraÃ§Ã£o

Desacopla modelo de API

Permite trocar LLM sem alterar backend

â“2. â€œIsso nÃ£o adiciona latÃªncia?â€
Resposta tÃ©cnica:

Sim, hÃ¡ uma camada extra.

Mas:

Ã‰ apenas uma chamada HTTP adicional

O overhead Ã© mÃ­nimo comparado ao tempo do LLM

Ganha-se governanÃ§a e padronizaÃ§Ã£o

LatÃªncia tÃ­pica extra: poucos milissegundos.

â“3. â€œE se o modelo chamar a tool errada?â€
Resposta:

O MCP nÃ£o decide.

A responsabilidade Ã©:

Prompt engineering

Tool descriptions claras

ValidaÃ§Ã£o no backend

Sempre valide no backend.
Nunca confie na IA.

â“4. â€œComo controlar escopo de tools por usuÃ¡rio?â€

Resposta madura:

NÃ£o esconda tools no MCP

Controle no backend via autorizaÃ§Ã£o

O backend Ã© a fonte de verdade

Opcionalmente:

Gerar servidores MCP por domÃ­nio

Usar middleware para bloquear tools

â“5. â€œComo versionar isso?â€

Boa pergunta sÃªnior.

Resposta:

Versione o OpenAPI

Versione o servidor MCP

Use tags no Git

Deploy via CI/CD normal

O MCP Ã© um microsserviÃ§o.

â“6. â€œComo escalar horizontalmente?â€

Resposta:

Stateless por padrÃ£o

Rodar mÃºltiplas rÃ©plicas

Redis se houver sessÃ£o

Load balancer na frente

â“7. â€œE se o Swagger mudar?â€

Resposta:

Recarregar no startup

Ou implementar cache

Ideal: CI valida contrato antes de deploy

â“8. â€œIsso Ã© seguro mesmo?â€

Resposta profissional:

Seguro se:

Nunca usar token global super admin

Nunca deixar LLM ver token real

Sempre validar backend

Usar HTTPS

Monitorar chamadas

Inseguro se usado como atalho.

â“9. â€œPosso usar isso como API Gateway?â€

Resposta:

NÃ£o completamente.

Ele Ã© um gateway para IA.
NÃ£o substitui Kong, Apigee, etc.

Mas pode complementar.

â“10. â€œIsso Ã© vendor lock-in da Anthropic?â€

Resposta:

NÃ£o.

MCP Ã© protocolo aberto.
Funciona com qualquer LLM que suporte tool calling.

ğŸ¯ Fechamento Forte para Devs

â€œO MCP nÃ£o Ã© moda.

Ã‰ a padronizaÃ§Ã£o da camada de integraÃ§Ã£o entre IA e sistemas.

Quem dominar isso vai definir como a empresa usa IA em produÃ§Ã£o.â€